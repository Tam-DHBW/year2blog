# Week 1

# jAilbreak â€“ Can You Outsmart the AI?

Weâ€™re building an experiment called jAilbreak.  
The idea is simple but fun: you land on a website where an AI is hiding a password from you.  
Your mission? Get it out of the AI using different jailbreaking methods.

---

## How It Works
Each level comes with stronger guardrails that try to stop you from getting what you want.  
- At the start, it might be as simple as asking the right way.  
- As you move up, the AI will get stricter.  
- Youâ€™ll need to use more creative jailbreaking techniques to break through.  

---

## Why Itâ€™s Interesting
Think of it as a mix between:  
- ðŸŽ® A puzzle game  
- ðŸ§  A crash course in prompt engineering  

Itâ€™s playful, but it also highlights how AI safety mechanisms workâ€”and how people can sometimes get around them.  

---

## Whatâ€™s Next
Weâ€™re still figuring out the best architecture and frameworks to power it.  
The goal is to make the experience:  
- âœ… Smooth  
- âœ… Scalable  
- âœ… Fun to learn from  

Stay tunedâ€”weâ€™ll be sharing progress as *jAilbreak* comes to life! ðŸš€

{{ #include comments.md }}
